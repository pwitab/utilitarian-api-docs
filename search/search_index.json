{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Utilitarian Documentation # Welcome to the Utilitarian documentation. Utilitarian is a multi utility AMR (Automatic Meter Reading) system that gives you and your organisation a simple way to manager AMR operations over multiple energy medias, protocol and metering equipment. In this documentation we we cover everything about the product and our on-premise offerings. Get started # To get a better grip on how Utilitarian and all its component works together check out the Architecture page. If you are interested in what type of communication protocols we support go to the Protocols page. We are continuously adding new meters that we support, and even if we haven't tried out your meters yet we might already support them due to our general protocol interpreters, or we need to do some work to get them into the system. To get info on the meters we have already verified against Utilitarian go to the meters page and if you need custom work done please contact us . As of now we are offering Utilitarian as an on-premise services. Our client base of utility companies usually prefer it this way. But keep a look out for the managed cloud version of Utilitarian. To know more about how to run Utilitarian check out the installation page. Get in contact # Simplest way of getting in contact with us is via email: info@pwit.se","title":"Home"},{"location":"#utilitarian-documentation","text":"Welcome to the Utilitarian documentation. Utilitarian is a multi utility AMR (Automatic Meter Reading) system that gives you and your organisation a simple way to manager AMR operations over multiple energy medias, protocol and metering equipment. In this documentation we we cover everything about the product and our on-premise offerings.","title":"Utilitarian Documentation"},{"location":"#get-started","text":"To get a better grip on how Utilitarian and all its component works together check out the Architecture page. If you are interested in what type of communication protocols we support go to the Protocols page. We are continuously adding new meters that we support, and even if we haven't tried out your meters yet we might already support them due to our general protocol interpreters, or we need to do some work to get them into the system. To get info on the meters we have already verified against Utilitarian go to the meters page and if you need custom work done please contact us . As of now we are offering Utilitarian as an on-premise services. Our client base of utility companies usually prefer it this way. But keep a look out for the managed cloud version of Utilitarian. To know more about how to run Utilitarian check out the installation page.","title":"Get started"},{"location":"#get-in-contact","text":"Simplest way of getting in contact with us is via email: info@pwit.se","title":"Get in contact"},{"location":"amr_um/","text":"Unified Messaging for Automatic Meter Readings # AMR UM is a project trying to define clearer messages that are focused on AMR operations. In metering it is common to use CIM (IEC 61968) to model your business processes and define messages for different type of operations. But it is all on quite high level. It is also a bit ambiguous how to use the models. There are several possiblities for the DSO (Distribution System Operators) to model the same data so focusing to comply with CIM in messages within Utilitarian would not be beneficial. Instead we are focusing on making clearly defined messages and document the usage well. We will if needed, provide translation services for CIM or other formats. But as of now it is up to the user to hook in to the message stream and get the data they need. We plan on sending all messages serialized using Avro and have a schema server for deserialization so that we can handle versioning of schemas. But this is a work in progress and for now we send messages in json format. We have developed a helper library in Python to build objects and make payloads for AMR UM messages: Check it out on GitHub Message Types # DLMS Push Message # Contains a push message (DataNotification) from a DLMS Meter { \"payload\" : \"base64encodedbytes\" , \"transport\" : \"udp\" , \"source_address\" : 'ip_address_of_origin' , \"source_port\" : 5678 , \"application_context\" : \"dsmr\" , \"dlms_wrapper\" : { \"source_wport\" : 1 , \"destiniation_wport\" : 10 , \"version\" : 1 } } New Meter Reading # Message containing a single meter reading { \"meter\" : \"FIOR78464920374\" , \"series\" : \"7-0-13-26-0-101\" , \"timestamp\" : \"2019-02-24T06:00:00T+01:00\" , \"value\" : \"14567.000\" }","title":"Messaging"},{"location":"amr_um/#unified-messaging-for-automatic-meter-readings","text":"AMR UM is a project trying to define clearer messages that are focused on AMR operations. In metering it is common to use CIM (IEC 61968) to model your business processes and define messages for different type of operations. But it is all on quite high level. It is also a bit ambiguous how to use the models. There are several possiblities for the DSO (Distribution System Operators) to model the same data so focusing to comply with CIM in messages within Utilitarian would not be beneficial. Instead we are focusing on making clearly defined messages and document the usage well. We will if needed, provide translation services for CIM or other formats. But as of now it is up to the user to hook in to the message stream and get the data they need. We plan on sending all messages serialized using Avro and have a schema server for deserialization so that we can handle versioning of schemas. But this is a work in progress and for now we send messages in json format. We have developed a helper library in Python to build objects and make payloads for AMR UM messages: Check it out on GitHub","title":"Unified Messaging for Automatic Meter Readings"},{"location":"amr_um/#message-types","text":"","title":"Message Types"},{"location":"amr_um/#dlms-push-message","text":"Contains a push message (DataNotification) from a DLMS Meter { \"payload\" : \"base64encodedbytes\" , \"transport\" : \"udp\" , \"source_address\" : 'ip_address_of_origin' , \"source_port\" : 5678 , \"application_context\" : \"dsmr\" , \"dlms_wrapper\" : { \"source_wport\" : 1 , \"destiniation_wport\" : 10 , \"version\" : 1 } }","title":"DLMS Push Message"},{"location":"amr_um/#new-meter-reading","text":"Message containing a single meter reading { \"meter\" : \"FIOR78464920374\" , \"series\" : \"7-0-13-26-0-101\" , \"timestamp\" : \"2019-02-24T06:00:00T+01:00\" , \"value\" : \"14567.000\" }","title":"New Meter Reading"},{"location":"architecture/","text":"Architecture # Utilitarian is a multi utility AMR system built for the Cloud. Multi utility # Utilitarian is built to manage any energy type, meter and communications protocol. Scalable # Utilitarian is a decentralized system that can be deployed across as many servers as needed to fit your use case. By using a message broker workloads are split across asynchronous worker processes for time consuming like polling for meter data. Workers can be scaled independently for fit your load. Receiving of push meter data is made in separate services that can all be individually scaled for the needed load. Reliable # Several instances can be run of every service and they can be run in different environments, for example if you want to split load between different data centers or availability zones Utilitarian does not limit you. Services can be load balanced using standard technologies. The main points of failure are the Postgres database and the RabbitMQ message broker, but these risks can be mitigated using High Availability (HA) setups and standard database reliability techniques. Secure # Depending on internal and regulatory requirements you can run Utilitarian with a range of security levels and settings so that you can find the best fit for your organization. Configurable # You can just run the services needed for your specific use case. Open # Utilitarian is designed to enable users to easily build their own integrations and subsystems if needed. It is possbile to hook into the message streams from any application using the message payload documentation. Utilitarian is built using open source technologies and libraries. We have also open sourced many of our own libraries that we use within Utilitarian.","title":"Overview"},{"location":"architecture/#architecture","text":"Utilitarian is a multi utility AMR system built for the Cloud.","title":"Architecture"},{"location":"architecture/#multi-utility","text":"Utilitarian is built to manage any energy type, meter and communications protocol.","title":"Multi utility"},{"location":"architecture/#scalable","text":"Utilitarian is a decentralized system that can be deployed across as many servers as needed to fit your use case. By using a message broker workloads are split across asynchronous worker processes for time consuming like polling for meter data. Workers can be scaled independently for fit your load. Receiving of push meter data is made in separate services that can all be individually scaled for the needed load.","title":"Scalable"},{"location":"architecture/#reliable","text":"Several instances can be run of every service and they can be run in different environments, for example if you want to split load between different data centers or availability zones Utilitarian does not limit you. Services can be load balanced using standard technologies. The main points of failure are the Postgres database and the RabbitMQ message broker, but these risks can be mitigated using High Availability (HA) setups and standard database reliability techniques.","title":"Reliable"},{"location":"architecture/#secure","text":"Depending on internal and regulatory requirements you can run Utilitarian with a range of security levels and settings so that you can find the best fit for your organization.","title":"Secure"},{"location":"architecture/#configurable","text":"You can just run the services needed for your specific use case.","title":"Configurable"},{"location":"architecture/#open","text":"Utilitarian is designed to enable users to easily build their own integrations and subsystems if needed. It is possbile to hook into the message streams from any application using the message payload documentation. Utilitarian is built using open source technologies and libraries. We have also open sourced many of our own libraries that we use within Utilitarian.","title":"Open"},{"location":"async_workers/","text":"Async Workers # Most of the heavy lifting in Utilitarian is made in asynchronous worker processes outside of the request-response cycle of the Utilitarian API. Tasks are transported to workers using RabbitMQ. Note We are using Celery to manage tasks and workers. You can learn a lot in their documentation on how to run and monitor tasks and workers. Queues # We separate different types of tasks on different queues. This makes you able to spin up more workers dedicated to certain queues depending on your load. If you start a worker without dedicated queues it will consume from all queues. Workers # A worker is a process that consumes tasks and execute them. Since the tasks are delivered via RabbitMQ you can split the processes up over several servers if you need to. It is possible to run a worker with increased concurrency. That means that the process will spawn several subprocess' to process tasks concurrently. The concurrency settings are something that might need tuning since you want to maximize your server utilization of CPU and memory and depending on the type of tasks (the queues) the workers consumes the load on the server might differ. It all depends on what kind of meters Utilitarian is reading and how many meters and at what frequency the readings are made. Since this can vary very much from customer to customer we cannot give you exact numbers on how to set up you workers but we will help you optimize for you unique circumstances. Run a worker # We use the same docker image as the Utilitarian API, with all the same settings. If you are using docker-compose you define utilitarian-worker : image : quay.io/pwit/utilitarian:version hostname : utilitarian-worker command : celery -A utilitarian worker --loglevel=INFO environment : *common_environment # unpacks settings so you only have to define it once in the docker-compose Beat # The beat process is the scheduler for scheduled or periodic tasks. Utilitarian has a number of maintenance tasks that needs to be run at certain intervals. The beat process is keeping control of when a task was run last and initiates new tasks when they are scheduled. It is also the beat process that initiates scheduled polling of meter data from polled meters. Only run one single beat process. If not you will end up with duplicate tasks. Duplicate tasks are usually ok, but will increase load on the system and might lead to higher operations costs such as data transfer cost. Run the beat process # utilitarian-beat : image : quay.io/pwit/utilitarian:version hostname : utilitarian-beat command : celery -A utilitarian beat --loglevel=INFO environment : *common_environment # unpacks settings so you only have to define it once in the docker-compose","title":"Async Workers"},{"location":"async_workers/#async-workers","text":"Most of the heavy lifting in Utilitarian is made in asynchronous worker processes outside of the request-response cycle of the Utilitarian API. Tasks are transported to workers using RabbitMQ. Note We are using Celery to manage tasks and workers. You can learn a lot in their documentation on how to run and monitor tasks and workers.","title":"Async Workers"},{"location":"async_workers/#queues","text":"We separate different types of tasks on different queues. This makes you able to spin up more workers dedicated to certain queues depending on your load. If you start a worker without dedicated queues it will consume from all queues.","title":"Queues"},{"location":"async_workers/#workers","text":"A worker is a process that consumes tasks and execute them. Since the tasks are delivered via RabbitMQ you can split the processes up over several servers if you need to. It is possible to run a worker with increased concurrency. That means that the process will spawn several subprocess' to process tasks concurrently. The concurrency settings are something that might need tuning since you want to maximize your server utilization of CPU and memory and depending on the type of tasks (the queues) the workers consumes the load on the server might differ. It all depends on what kind of meters Utilitarian is reading and how many meters and at what frequency the readings are made. Since this can vary very much from customer to customer we cannot give you exact numbers on how to set up you workers but we will help you optimize for you unique circumstances.","title":"Workers"},{"location":"async_workers/#run-a-worker","text":"We use the same docker image as the Utilitarian API, with all the same settings. If you are using docker-compose you define utilitarian-worker : image : quay.io/pwit/utilitarian:version hostname : utilitarian-worker command : celery -A utilitarian worker --loglevel=INFO environment : *common_environment # unpacks settings so you only have to define it once in the docker-compose","title":"Run a worker"},{"location":"async_workers/#beat","text":"The beat process is the scheduler for scheduled or periodic tasks. Utilitarian has a number of maintenance tasks that needs to be run at certain intervals. The beat process is keeping control of when a task was run last and initiates new tasks when they are scheduled. It is also the beat process that initiates scheduled polling of meter data from polled meters. Only run one single beat process. If not you will end up with duplicate tasks. Duplicate tasks are usually ok, but will increase load on the system and might lead to higher operations costs such as data transfer cost.","title":"Beat"},{"location":"async_workers/#run-the-beat-process","text":"utilitarian-beat : image : quay.io/pwit/utilitarian:version hostname : utilitarian-beat command : celery -A utilitarian beat --loglevel=INFO environment : *common_environment # unpacks settings so you only have to define it once in the docker-compose","title":"Run the beat process"},{"location":"component_settings/","text":"Component Settings # Our docker images are handed settings via Environment Variables Utilitarian API # UTILITARIAN_DEBUG # Enables debugging features. Defaults to False . Warning Do not use in production! UTILITARIAN_LOGLEVEL # Sets the loglevel of the application. Valid inputs are: debug , info , warning , error , critical . Defaults to info DATABASE_URL # Connection string to Postgres database. SECRET_KEY # Used for internal cryptographic signing and cryptographic methods. Should be generated once at first deploy time. Recommended length is 50 characters. Warning The SECRET_KEY plays an important role in securing the application. Make sure it remains secret. ALLOWED_HOSTS # A list of allowed host for the application. The application will only accept requests with a host in this list. Example: example.com, 127.0.0.1 . ACCOUNT_ALLOW_REGISTRATION # If you want to allow user registration in the application. Defaults to False . AMQP_CONNECTION_STRING # AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// . AMQP_PUBLISH_TO # RabbitMQ exchange where messages from Utilitarian API is published. SECURE_SSL_REDIRECT # It is better to use DNS or a reverse proxy for this functionality but if that is not possible setting to True will redirect all non HTTPS requests to HTTPS. Defaults to False . SECURE_HSTS_SECONDS # If set to a non-zero integer value the application will set the HTTP Strict Transport Security header on all responses that do not already have it. This will tell browsers and clients that the application is only to be served under HTTPS. When enabling you should always set to a low value (60) and increase it after it works. Defaults to 0 . Warning Using this setting wrongly can make your application unaccessable for quite some time. Please see the full documentation of this feature before doing any changes. SECURE_CONTENT_TYPE_NOSNIFF # If True, Utilitarian API sets the X-Content-Type-Options: nosniff header on all responses that do not already have it. Defaults to True . SECURE_BROWSER_XSS_FILTER # If True, Utilitarian API sets the X-XSS-Protection: 1; mode=block header on all responses that do not already have it. Defaults to True . SESSION_COOKIE_SECURE # Whether to use a secure cookie for the session cookie. If this is set to True, the cookie will be marked as \u201csecure,\u201d which means browsers may ensure that the cookie is only sent under an HTTPS connection. Defaults to False . CSRF_COOKIE_SECURE # Whether to use a secure cookie for the CSRF cookie. If this is set to True, the cookie will be marked as \u201csecure,\u201d which means browsers may ensure that the cookie is only sent under an HTTPS connection. Defaults to False . USE_X_FORWARDED_HOST # A boolean that specifies whether to use the X-Forwarded-Host header in preference to the Host header. This should only be enabled if a proxy which sets this header is in use. This setting takes priority over USE_X_FORWARDED_PORT. Per RFC 7239#page-7 , the X-Forwarded-Host header can include the port number, in which case you shouldn\u2019t use USE_X_FORWARDED_PORT. Defaults to False . USE_X_FORWARDED_PORT # A boolean that specifies whether to use the X-Forwarded-Port header in preference to the SERVER_PORT META variable. This should only be enabled if a proxy which sets this header is in use. USE_X_FORWARDED_HOST takes priority over this setting. USE_X_FORWARDED_PROTO # X-Forwarded-Proto header that comes from our proxy, and any time its value is 'https', then the request is guaranteed to be secure (i.e., it originally came in via HTTPS). You should only set this setting if you control your proxy or have some other guarantee that it sets/strips this header appropriately Defaults to False Warning Modifying this setting can compromise your Utilitarian API\u2019s security. Ensure you fully understand your setup before changing it. Make sure ALL of the following are true before setting this (assuming the values from the example above): Your Utilitarian API is behind a proxy. Your proxy strips the X-Forwarded-Proto header from all incoming requests. In other words, if end users include that header in their requests, the proxy will discard it. Your proxy sets the X-Forwarded-Proto header and sends it to Utilitarian API, but only for requests that originally come in via HTTPS. If any of those are not true, you should keep this setting set to False. HEALTHCHECK_DISABLED # Disables the health check endpoint /_health/ Defaults to False DATA_RETENTION_DAYS # Sets the amount of days you want to keep data in Utilitarian. Only affects time series data as meter readings and meter system events. For example: 365 days in a year. If you want to keep all data that is younger than 2 years and discard everything that is older than 2 years you would set DATA_RETENTION_DAYS=730 . If the environment variable is not set data is kept forever. Defaults to None STAGED_DATA_RETENTION_DAYS # Sets the amount of days you want to keep staged data in Utilitarian. For example staged meter readings. It is assumed that staged data is short lived so you shouldn't have to long data retention for staged data. Defaults to 30 days UTILITARIAN_TIME_ZONE # Local time zone for this installation. Choices can be found here: http://en.wikipedia.org/wiki/List_of_tz_zones_by_name although not all choices may be available on all operating systems. Utilitarian still handles all datetimes as time zone aware internally. This setting should only be changed if you are fully aware of the implications. Defaults to 'UTC' DLMS UDP Server # DLMS_UDP_SERVER_DEBUG # Will set the loglevel to debug. Defaults to False AMQP_CONNECTION_STRING # AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// . AMQP_EXCHANGE_NAME # The exchange where messages will be published. Defaults to utilitarian AMQP_DEFAULT_QUEUE_NAME # To ensure that the broker always have a queue that will receive our messages we declare in both publishers and subscribers. This is the name of the queue. Defaults to utilitarian.dlms_push_messages AMQP_DEFAULT_QUEUE_ROUTING_KEY # The routing key we want to bind to the default key. Defaults to new_dlms_push_message.#\"` UTILITARIAN_APPLICATION_CONTEXT # Since there are a few different variations (companion standards) to DLMS/COSEM and some implements some things differntly we add the application context of receiving server to add it to any outgoing messages. You should run a separate instance of the UDP server for each different application context. It is not possible to see in the messages what companion standard the meter is using so we separate them by setting them up against different server. Defaults to units11291 DLMS PROCESSOR # DLMS_CONSUMER_DEBUG # Will set the loglevel to debug. Defaults to False AMQP_CONNECTION_STRING # AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// . DLMS_CONSUMER_CONSUME_FROM # The queue from where to consume messages. Defaults to utilitarian.dlms_push_messages DLMS_CONSUMER_PREFETCH_COUNT # The consumer prefetch count, how many unacknowledged messages the consumer is allowed to have in memory. Default to 100 DLMS_CONSUMER_PUBLISH_TO # Exchange to publish meter readings to. Defaults to utilitarian UTILITARIAN_BASE_URL # The base url for Utilitarian API. Example: https://utilitarian.example.com:8000 UTILITARIAN_AUTH_TOKEN # Token for authentication to Utilitarian API. Example: 9c72cba03f4920dcb4b62c4d2723fe5718990024 UTILITARIAN_REQUEST_TIMEOUT # Request timeout for HTTP calls to Utilitarian API. IF you start seeing a high rate of TimeoutErrors your database might not have enough resources or you need to load balance the API. But increasing the timeout could solve you problems short-term. Defined in seconds Defaults to 15 Utilitarian Poster # POSTER_DEBUG # Enables debug. Sets loglevel to debug Defaults to False AMQP_CONNECTION_STRING # AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// . POSTER_CONSUME_FROM # Name of the queues to consume from. Defaults to utilitarian.new_meter_readings POSTER_PREFETCH_COUNT # The consumer prefetch count, how many unacknowledged messages the consumer is allowed to have in memory. Default to 100 UTILITARIAN_BASE_URL # The base url for Utilitarian API. Example: https://utilitarian.example.com:8000 UTILITARIAN_AUTH_TOKEN # Token for authentication to Utilitarian API. Example: 9c72cba03f4920dcb4b62c4d2723fe5718990024 UTILITARIAN_REQUEST_TIMEOUT # Request timeout for HTTP calls to Utilitarian API. IF you start seeing a high rate of TimeoutErrors your database might not have enough resources or you need to load balance the API. But increasing the timeout could solve you problems short-term. Defined in seconds Defaults to 15","title":"Component Configuration"},{"location":"component_settings/#component-settings","text":"Our docker images are handed settings via Environment Variables","title":"Component Settings"},{"location":"component_settings/#utilitarian-api","text":"","title":"Utilitarian API"},{"location":"component_settings/#utilitarian_debug","text":"Enables debugging features. Defaults to False . Warning Do not use in production!","title":"UTILITARIAN_DEBUG"},{"location":"component_settings/#utilitarian_loglevel","text":"Sets the loglevel of the application. Valid inputs are: debug , info , warning , error , critical . Defaults to info","title":"UTILITARIAN_LOGLEVEL"},{"location":"component_settings/#database_url","text":"Connection string to Postgres database.","title":"DATABASE_URL"},{"location":"component_settings/#secret_key","text":"Used for internal cryptographic signing and cryptographic methods. Should be generated once at first deploy time. Recommended length is 50 characters. Warning The SECRET_KEY plays an important role in securing the application. Make sure it remains secret.","title":"SECRET_KEY"},{"location":"component_settings/#allowed_hosts","text":"A list of allowed host for the application. The application will only accept requests with a host in this list. Example: example.com, 127.0.0.1 .","title":"ALLOWED_HOSTS"},{"location":"component_settings/#account_allow_registration","text":"If you want to allow user registration in the application. Defaults to False .","title":"ACCOUNT_ALLOW_REGISTRATION"},{"location":"component_settings/#amqp_connection_string","text":"AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// .","title":"AMQP_CONNECTION_STRING"},{"location":"component_settings/#amqp_publish_to","text":"RabbitMQ exchange where messages from Utilitarian API is published.","title":"AMQP_PUBLISH_TO"},{"location":"component_settings/#secure_ssl_redirect","text":"It is better to use DNS or a reverse proxy for this functionality but if that is not possible setting to True will redirect all non HTTPS requests to HTTPS. Defaults to False .","title":"SECURE_SSL_REDIRECT"},{"location":"component_settings/#secure_hsts_seconds","text":"If set to a non-zero integer value the application will set the HTTP Strict Transport Security header on all responses that do not already have it. This will tell browsers and clients that the application is only to be served under HTTPS. When enabling you should always set to a low value (60) and increase it after it works. Defaults to 0 . Warning Using this setting wrongly can make your application unaccessable for quite some time. Please see the full documentation of this feature before doing any changes.","title":"SECURE_HSTS_SECONDS"},{"location":"component_settings/#secure_content_type_nosniff","text":"If True, Utilitarian API sets the X-Content-Type-Options: nosniff header on all responses that do not already have it. Defaults to True .","title":"SECURE_CONTENT_TYPE_NOSNIFF"},{"location":"component_settings/#secure_browser_xss_filter","text":"If True, Utilitarian API sets the X-XSS-Protection: 1; mode=block header on all responses that do not already have it. Defaults to True .","title":"SECURE_BROWSER_XSS_FILTER"},{"location":"component_settings/#session_cookie_secure","text":"Whether to use a secure cookie for the session cookie. If this is set to True, the cookie will be marked as \u201csecure,\u201d which means browsers may ensure that the cookie is only sent under an HTTPS connection. Defaults to False .","title":"SESSION_COOKIE_SECURE"},{"location":"component_settings/#csrf_cookie_secure","text":"Whether to use a secure cookie for the CSRF cookie. If this is set to True, the cookie will be marked as \u201csecure,\u201d which means browsers may ensure that the cookie is only sent under an HTTPS connection. Defaults to False .","title":"CSRF_COOKIE_SECURE"},{"location":"component_settings/#use_x_forwarded_host","text":"A boolean that specifies whether to use the X-Forwarded-Host header in preference to the Host header. This should only be enabled if a proxy which sets this header is in use. This setting takes priority over USE_X_FORWARDED_PORT. Per RFC 7239#page-7 , the X-Forwarded-Host header can include the port number, in which case you shouldn\u2019t use USE_X_FORWARDED_PORT. Defaults to False .","title":"USE_X_FORWARDED_HOST"},{"location":"component_settings/#use_x_forwarded_port","text":"A boolean that specifies whether to use the X-Forwarded-Port header in preference to the SERVER_PORT META variable. This should only be enabled if a proxy which sets this header is in use. USE_X_FORWARDED_HOST takes priority over this setting.","title":"USE_X_FORWARDED_PORT"},{"location":"component_settings/#use_x_forwarded_proto","text":"X-Forwarded-Proto header that comes from our proxy, and any time its value is 'https', then the request is guaranteed to be secure (i.e., it originally came in via HTTPS). You should only set this setting if you control your proxy or have some other guarantee that it sets/strips this header appropriately Defaults to False Warning Modifying this setting can compromise your Utilitarian API\u2019s security. Ensure you fully understand your setup before changing it. Make sure ALL of the following are true before setting this (assuming the values from the example above): Your Utilitarian API is behind a proxy. Your proxy strips the X-Forwarded-Proto header from all incoming requests. In other words, if end users include that header in their requests, the proxy will discard it. Your proxy sets the X-Forwarded-Proto header and sends it to Utilitarian API, but only for requests that originally come in via HTTPS. If any of those are not true, you should keep this setting set to False.","title":"USE_X_FORWARDED_PROTO"},{"location":"component_settings/#healthcheck_disabled","text":"Disables the health check endpoint /_health/ Defaults to False","title":"HEALTHCHECK_DISABLED"},{"location":"component_settings/#data_retention_days","text":"Sets the amount of days you want to keep data in Utilitarian. Only affects time series data as meter readings and meter system events. For example: 365 days in a year. If you want to keep all data that is younger than 2 years and discard everything that is older than 2 years you would set DATA_RETENTION_DAYS=730 . If the environment variable is not set data is kept forever. Defaults to None","title":"DATA_RETENTION_DAYS"},{"location":"component_settings/#staged_data_retention_days","text":"Sets the amount of days you want to keep staged data in Utilitarian. For example staged meter readings. It is assumed that staged data is short lived so you shouldn't have to long data retention for staged data. Defaults to 30 days","title":"STAGED_DATA_RETENTION_DAYS"},{"location":"component_settings/#utilitarian_time_zone","text":"Local time zone for this installation. Choices can be found here: http://en.wikipedia.org/wiki/List_of_tz_zones_by_name although not all choices may be available on all operating systems. Utilitarian still handles all datetimes as time zone aware internally. This setting should only be changed if you are fully aware of the implications. Defaults to 'UTC'","title":"UTILITARIAN_TIME_ZONE"},{"location":"component_settings/#dlms-udp-server","text":"","title":"DLMS UDP Server"},{"location":"component_settings/#dlms_udp_server_debug","text":"Will set the loglevel to debug. Defaults to False","title":"DLMS_UDP_SERVER_DEBUG"},{"location":"component_settings/#amqp_connection_string_1","text":"AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// .","title":"AMQP_CONNECTION_STRING"},{"location":"component_settings/#amqp_exchange_name","text":"The exchange where messages will be published. Defaults to utilitarian","title":"AMQP_EXCHANGE_NAME"},{"location":"component_settings/#amqp_default_queue_name","text":"To ensure that the broker always have a queue that will receive our messages we declare in both publishers and subscribers. This is the name of the queue. Defaults to utilitarian.dlms_push_messages","title":"AMQP_DEFAULT_QUEUE_NAME"},{"location":"component_settings/#amqp_default_queue_routing_key","text":"The routing key we want to bind to the default key. Defaults to new_dlms_push_message.#\"`","title":"AMQP_DEFAULT_QUEUE_ROUTING_KEY"},{"location":"component_settings/#utilitarian_application_context","text":"Since there are a few different variations (companion standards) to DLMS/COSEM and some implements some things differntly we add the application context of receiving server to add it to any outgoing messages. You should run a separate instance of the UDP server for each different application context. It is not possible to see in the messages what companion standard the meter is using so we separate them by setting them up against different server. Defaults to units11291","title":"UTILITARIAN_APPLICATION_CONTEXT"},{"location":"component_settings/#dlms-processor","text":"","title":"DLMS PROCESSOR"},{"location":"component_settings/#dlms_consumer_debug","text":"Will set the loglevel to debug. Defaults to False","title":"DLMS_CONSUMER_DEBUG"},{"location":"component_settings/#amqp_connection_string_2","text":"AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// .","title":"AMQP_CONNECTION_STRING"},{"location":"component_settings/#dlms_consumer_consume_from","text":"The queue from where to consume messages. Defaults to utilitarian.dlms_push_messages","title":"DLMS_CONSUMER_CONSUME_FROM"},{"location":"component_settings/#dlms_consumer_prefetch_count","text":"The consumer prefetch count, how many unacknowledged messages the consumer is allowed to have in memory. Default to 100","title":"DLMS_CONSUMER_PREFETCH_COUNT"},{"location":"component_settings/#dlms_consumer_publish_to","text":"Exchange to publish meter readings to. Defaults to utilitarian","title":"DLMS_CONSUMER_PUBLISH_TO"},{"location":"component_settings/#utilitarian_base_url","text":"The base url for Utilitarian API. Example: https://utilitarian.example.com:8000","title":"UTILITARIAN_BASE_URL"},{"location":"component_settings/#utilitarian_auth_token","text":"Token for authentication to Utilitarian API. Example: 9c72cba03f4920dcb4b62c4d2723fe5718990024","title":"UTILITARIAN_AUTH_TOKEN"},{"location":"component_settings/#utilitarian_request_timeout","text":"Request timeout for HTTP calls to Utilitarian API. IF you start seeing a high rate of TimeoutErrors your database might not have enough resources or you need to load balance the API. But increasing the timeout could solve you problems short-term. Defined in seconds Defaults to 15","title":"UTILITARIAN_REQUEST_TIMEOUT"},{"location":"component_settings/#utilitarian-poster","text":"","title":"Utilitarian Poster"},{"location":"component_settings/#poster_debug","text":"Enables debug. Sets loglevel to debug Defaults to False","title":"POSTER_DEBUG"},{"location":"component_settings/#amqp_connection_string_3","text":"AMQP Connection string to RabbitMQ broker. Example: amqp://guest:guest@rabbitmq:5672// .","title":"AMQP_CONNECTION_STRING"},{"location":"component_settings/#poster_consume_from","text":"Name of the queues to consume from. Defaults to utilitarian.new_meter_readings","title":"POSTER_CONSUME_FROM"},{"location":"component_settings/#poster_prefetch_count","text":"The consumer prefetch count, how many unacknowledged messages the consumer is allowed to have in memory. Default to 100","title":"POSTER_PREFETCH_COUNT"},{"location":"component_settings/#utilitarian_base_url_1","text":"The base url for Utilitarian API. Example: https://utilitarian.example.com:8000","title":"UTILITARIAN_BASE_URL"},{"location":"component_settings/#utilitarian_auth_token_1","text":"Token for authentication to Utilitarian API. Example: 9c72cba03f4920dcb4b62c4d2723fe5718990024","title":"UTILITARIAN_AUTH_TOKEN"},{"location":"component_settings/#utilitarian_request_timeout_1","text":"Request timeout for HTTP calls to Utilitarian API. IF you start seeing a high rate of TimeoutErrors your database might not have enough resources or you need to load balance the API. But increasing the timeout could solve you problems short-term. Defined in seconds Defaults to 15","title":"UTILITARIAN_REQUEST_TIMEOUT"},{"location":"components/","text":"Components in Utilitarian # Utilitarian API # The main application for Utilitarian. It stores all data and handles all scheduling of reading jobs. We provide a REST API to manage the data and jobs. docker pull quay.io/pwit/utilitarian:version See component settings on how to configure Utilitarian API DLMS UDP Server # A high throughput UDP server to receive DLMS DataNotifications from meters. docker pull quay.io/pwit/utilitarian-dlms-udp-server:version DLMS Processor # Many DLMS push messages are encrypted and to decrypt UDP messages in the receiving server would reduce throughput and we could loose messages if the server is not available to process them. Instead the UDP server sends the DLMS messages to the message broker and they are consumed by the DLMS Processor where they get decrypted and parsed into Meter Readings that is published back to the message broker. docker pull quay.io/pwit/utilitarian-dlms-processor:version Utilitarian Poster # The Utilitarian poster is a queue consumer that will receive all data that are to be saved in the Utilitarian API and send it over HTTP to the correct endpoint. docker pull quay.io/pwit/utilitarian-poster:version Database # Utilitarian uses PostgreSQL as database. Message Broker # Utilitarian uses RabbitMQ as message broker.","title":"Components"},{"location":"components/#components-in-utilitarian","text":"","title":"Components in Utilitarian"},{"location":"components/#utilitarian-api","text":"The main application for Utilitarian. It stores all data and handles all scheduling of reading jobs. We provide a REST API to manage the data and jobs. docker pull quay.io/pwit/utilitarian:version See component settings on how to configure Utilitarian API","title":"Utilitarian API"},{"location":"components/#dlms-udp-server","text":"A high throughput UDP server to receive DLMS DataNotifications from meters. docker pull quay.io/pwit/utilitarian-dlms-udp-server:version","title":"DLMS UDP Server"},{"location":"components/#dlms-processor","text":"Many DLMS push messages are encrypted and to decrypt UDP messages in the receiving server would reduce throughput and we could loose messages if the server is not available to process them. Instead the UDP server sends the DLMS messages to the message broker and they are consumed by the DLMS Processor where they get decrypted and parsed into Meter Readings that is published back to the message broker. docker pull quay.io/pwit/utilitarian-dlms-processor:version","title":"DLMS Processor"},{"location":"components/#utilitarian-poster","text":"The Utilitarian poster is a queue consumer that will receive all data that are to be saved in the Utilitarian API and send it over HTTP to the correct endpoint. docker pull quay.io/pwit/utilitarian-poster:version","title":"Utilitarian Poster"},{"location":"components/#database","text":"Utilitarian uses PostgreSQL as database.","title":"Database"},{"location":"components/#message-broker","text":"Utilitarian uses RabbitMQ as message broker.","title":"Message Broker"},{"location":"docker_compose/","text":"Setting up with docker-compose # Install docker-compose # Easiest is to use pip pip install docker-compose Define docker-compose file # Create a new docker-compose.yaml file touch docker-compose.yaml Define all services with environment variables and volumes if needed. Note We are using docker containers for Postgres and RabbitMQ just to show the system as a whole. You don't need to run them in containers, as we except just the connection string as input to the other services. # Example docker compose containers for Utiltarian version : '3' services : rabbitmq : image : rabbitmq:3-management restart : unless-stopped ports : - \"5672:5672\" - \"15672:15672\" postgres : image : postgres:10.7-apline restart : unless-stopped ports : - \"15432:5432\" volumes : - postgres_data:/var/lib/postgresql/data/ utilitarian-api : image : quay.io/pwit/utilitarian:vx.x.x restart : unless-stopped ports : - \"8000:8000\" depends_on : - rabbitmq - postgres environment : &utilitarian_env # Debug # SECURITY WARNING: Don't use in production - UTILITARIAN_DEBUG=false - UTILITARIAN_LOGLEVEL=debug - # General settings - DATABASE_URL=postgres://postgres/dbname - SECRET_KEY=verysecretkey - ALLOWED_HOSTS=utilitarian-api - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ utilitarian-worker : image : quay.io/pwit/utilitarian:version restart : unless-stopped command : celery -A utilitarian worker --loglevel=INFO environment : *utilitarian_env # anchor it to api to only define once. utilitarian-beat : image : quay.io/pwit/utilitarian:version restart : unless-stopped command : celery -A utilitarian beat --loglevel=INFO environment : *utilitarian_env # anchor it to api to only define once. dlms-processor : image : quay.io/pwit/utilitarian-dlms-processor:vX.X.X restart : unless-stopped depends_on : - rabbitmq - utilitarian-api environment : - DLMS_CONSUMER_DEBUG=false - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ - DLMS_CONSUMER_CONSUME_FROM=utilitarian.dlms_push_messages - DLMS_CONSUMER_PREFETCH_COUNT=100 - DLMS_CONSUMER_PUBLISH_TO=utilitarian - UTILITARIAN_BASE_URL=http://utilitarian-api:8000 - UTILITARIAN_AUTH_TOKEN=024281a8c6a12b5fb5a8445439bb9236555975fe - UTILITARIAN_REQUEST_TIMEOUT=15 dlms-udp-server : image : quay.io/pwit/utilitarian-dlms-udp-server:vX.X.X restart : unless-stopped ports : # You need to specify that it is an UDP port and not TCP! - '4059:4059/udp' depends_on : - rabbitmq environment : - DLMS_UDP_SERVER_DEBUG=false - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ - AMQP_EXCHANGE_NAME=utilitarian - AMQP_DEFAULT_QUEUE_NAME=utilitarian.dlms_push_messages - AMQP_DEFAULT_QUEUE_ROUTING_KEY=\"new_dlms_push_message.#\" - UTILITARIAN_APPLICATION_CONTEXT=units11291 utilitarian-poster : image : quay.io/pwit/utilitarian-poster:vX.X.X restart : unless-stopped depends_on : - rabbitmq - utilitarian-api environment : - POSTER_DEBUG=false - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ - POSTER_CONSUME_FROM=utilitarian.new_meter_readings - POSTER_PREFETCH_COUNT=100 - UTILITARIAN_BASE_URL=http://utilitarian-api:8000 - UTILITARIAN_AUTH_TOKEN=024281a8c6a12b5fb5a8445439bb9236555975fe - UTILITARIAN_REQUEST_TIMEOUT=15 volumes : - postgres_data : Note Do not name your service names using underscores. For example the host for making HTTP requests will become something_something and having underscore in HTTP_HOST header is not valid according to RFC 1034/1035. It will result in an error.","title":"Setup using Docker Compose"},{"location":"docker_compose/#setting-up-with-docker-compose","text":"","title":"Setting up with docker-compose"},{"location":"docker_compose/#install-docker-compose","text":"Easiest is to use pip pip install docker-compose","title":"Install docker-compose"},{"location":"docker_compose/#define-docker-compose-file","text":"Create a new docker-compose.yaml file touch docker-compose.yaml Define all services with environment variables and volumes if needed. Note We are using docker containers for Postgres and RabbitMQ just to show the system as a whole. You don't need to run them in containers, as we except just the connection string as input to the other services. # Example docker compose containers for Utiltarian version : '3' services : rabbitmq : image : rabbitmq:3-management restart : unless-stopped ports : - \"5672:5672\" - \"15672:15672\" postgres : image : postgres:10.7-apline restart : unless-stopped ports : - \"15432:5432\" volumes : - postgres_data:/var/lib/postgresql/data/ utilitarian-api : image : quay.io/pwit/utilitarian:vx.x.x restart : unless-stopped ports : - \"8000:8000\" depends_on : - rabbitmq - postgres environment : &utilitarian_env # Debug # SECURITY WARNING: Don't use in production - UTILITARIAN_DEBUG=false - UTILITARIAN_LOGLEVEL=debug - # General settings - DATABASE_URL=postgres://postgres/dbname - SECRET_KEY=verysecretkey - ALLOWED_HOSTS=utilitarian-api - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ utilitarian-worker : image : quay.io/pwit/utilitarian:version restart : unless-stopped command : celery -A utilitarian worker --loglevel=INFO environment : *utilitarian_env # anchor it to api to only define once. utilitarian-beat : image : quay.io/pwit/utilitarian:version restart : unless-stopped command : celery -A utilitarian beat --loglevel=INFO environment : *utilitarian_env # anchor it to api to only define once. dlms-processor : image : quay.io/pwit/utilitarian-dlms-processor:vX.X.X restart : unless-stopped depends_on : - rabbitmq - utilitarian-api environment : - DLMS_CONSUMER_DEBUG=false - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ - DLMS_CONSUMER_CONSUME_FROM=utilitarian.dlms_push_messages - DLMS_CONSUMER_PREFETCH_COUNT=100 - DLMS_CONSUMER_PUBLISH_TO=utilitarian - UTILITARIAN_BASE_URL=http://utilitarian-api:8000 - UTILITARIAN_AUTH_TOKEN=024281a8c6a12b5fb5a8445439bb9236555975fe - UTILITARIAN_REQUEST_TIMEOUT=15 dlms-udp-server : image : quay.io/pwit/utilitarian-dlms-udp-server:vX.X.X restart : unless-stopped ports : # You need to specify that it is an UDP port and not TCP! - '4059:4059/udp' depends_on : - rabbitmq environment : - DLMS_UDP_SERVER_DEBUG=false - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ - AMQP_EXCHANGE_NAME=utilitarian - AMQP_DEFAULT_QUEUE_NAME=utilitarian.dlms_push_messages - AMQP_DEFAULT_QUEUE_ROUTING_KEY=\"new_dlms_push_message.#\" - UTILITARIAN_APPLICATION_CONTEXT=units11291 utilitarian-poster : image : quay.io/pwit/utilitarian-poster:vX.X.X restart : unless-stopped depends_on : - rabbitmq - utilitarian-api environment : - POSTER_DEBUG=false - AMQP_CONNECTION_STRING=amqp://guest:guest@rabbitmq:5672/ - POSTER_CONSUME_FROM=utilitarian.new_meter_readings - POSTER_PREFETCH_COUNT=100 - UTILITARIAN_BASE_URL=http://utilitarian-api:8000 - UTILITARIAN_AUTH_TOKEN=024281a8c6a12b5fb5a8445439bb9236555975fe - UTILITARIAN_REQUEST_TIMEOUT=15 volumes : - postgres_data : Note Do not name your service names using underscores. For example the host for making HTTP requests will become something_something and having underscore in HTTP_HOST header is not valid according to RFC 1034/1035. It will result in an error.","title":"Define docker-compose file"},{"location":"installation/","text":"On Premise # How to install and run Utilitarian Requirements # Utilitarian depends on the following systems: Postgres 10 RabbitMQ Docker # All Utilitarian components are distributed via docker images. When you have purchased a Utilitarian License you will get a login account to be able to fetch the images via docker-cli . As of now all PWIT docker images are stored in Quay and you will need to use the credentials supplied by us to log in and pull the images. $ docker login quay.io Login against server at https://quay.io/v1/ Username: pwitab+yourpullaccount Password: ThePasswordGivenToYouFromPWIT Email: any@example.com Once you have logged in you can pull the images. docker pull quay.io/pwit/repo-name:version Installation # We will provide information on how to install and run the applications via docker-compose . In the future we will also provide instructions for Kubernetes. Docker compose might not be the right tool to for you depending on your installation and system requirements but it is a good starting point and you will get a lot of insight on how to run the systems via this instruction. If you need assistance running Utilitarian in another environment please contact us . Postgres # We use Postgres as our database of choice. We recommend that you set up Postgres on a dedicated server or use a managed service for it. You can find out a lot about running Postgres online . Also make sure you have proper security settings and follow best practices. If you are running Postgres yourself you also want to set up a stable backup function . After you have set up postgres you will supply the connection string in the format: postgres://[user[:password]@][host][:port][,...][/dbname][?param1=value1&...] # Example postgres://myuser:mysecretpassword@localhost:5432/db_name Postgres is available as a docker container and if you also want to run Postgres via docker make sure you set up a volume for it so that you don't loose any of your data. docker pull postgres:10.7-alpine RabbitMQ # RabbitMQ is a message broker for the AMQP protocol. Utilitarian uses it for inter-application communication and data processing. Checkout the official RabbitMQ site to learn how to run RabbitMQ or purchase a managed solution from, for example CloudAMQP . You will need to provide a similar connection string for RabbitMQ as for Postgres: amqp://[user[:password]@][host][:port][/vhost]] # Example amqp://guest:guest@localhost:5672// RabbitMQ can also be run as a container. Just be sure to add a volume for it so you don't loose any data and we recommend that you include the management plugin so that you have an interface for management and debugging if something is not working correctly. docker pull rabbitmq:3.7.13-management-alpine Hardware # We don\u2019t have any real numbers to tell you what kind of hardware you\u2019re going to need, but we\u2019ll help you make your decision based on existing usage from real customers. It all depends on how many meters you are managing in Utilitarian and how much data you collect from them. If you have a wide range of different meters you must also take into consideration that you will have multiple services of different kinds running in your environment. We provide means to scale horizontally but the database is still the single point of failure. Since you are free to set up the database the way your IT department or Ops team requires we leave this implementation detail to the customer. Monitoring # We do not supply a standard solution to monitor the applications. All logs from the different applications are outputed on stdout via docker. So they are accessible via docker logs. You can then hook up the docker logs to different logging drivers, see the official docker documentation . There are several solutions to application and log monitoring. For example Elastic Stack or Splunk. Contact us if you want help setting this up for your installation. We are exposing a healthcheck endpoint at /_health/ that will return 200 OK if the the API is working correctly. The healthcheck can be disabled using the env variable HEALTHCHECK_DISABLED Initial setup Utilitarian API # Generate application SECRET_KEY # Utilitarian needs a SECRET_KEY for cryptographic algorithms and signing. We recommend at least 50 chars. # Example generating SECRET_KEY with openssl openssl rand -base64 50 >> CZKcDahINwxy+eYzMItr+NZRqrONvMmJ12g+hF+W/QOMh/A4tRxhQ3onvRjJv47l Set the SECRET_KEY environment variable to this key. Migrate the database # The first time you set up Utilitarian API you will need to migrate the database so all tables are present. Assuming you have started all services via docker-compose run the following command: docker-compose exec utilitarian_api sh -c \"python manage.py migrate\" Create Superuser # Assuming you have started all services via docker-compose you should run the following command docker-compose exec utilitarian_api sh -c \"python manage.py createsuperuser\" Collect static assets # Assuming you have started all services via docker-compose you should run the following command docker-compose exec utilitarian_api sh -c \"python manage.py collectstatic --no-input\" Compress static assets # Assuming you have started all services via docker-compose you should run the following command docker-compose exec utilitarian_api sh -c \"python manage.py compress\"","title":"Installation"},{"location":"installation/#on-premise","text":"How to install and run Utilitarian","title":"On Premise"},{"location":"installation/#requirements","text":"Utilitarian depends on the following systems: Postgres 10 RabbitMQ","title":"Requirements"},{"location":"installation/#docker","text":"All Utilitarian components are distributed via docker images. When you have purchased a Utilitarian License you will get a login account to be able to fetch the images via docker-cli . As of now all PWIT docker images are stored in Quay and you will need to use the credentials supplied by us to log in and pull the images. $ docker login quay.io Login against server at https://quay.io/v1/ Username: pwitab+yourpullaccount Password: ThePasswordGivenToYouFromPWIT Email: any@example.com Once you have logged in you can pull the images. docker pull quay.io/pwit/repo-name:version","title":"Docker"},{"location":"installation/#installation","text":"We will provide information on how to install and run the applications via docker-compose . In the future we will also provide instructions for Kubernetes. Docker compose might not be the right tool to for you depending on your installation and system requirements but it is a good starting point and you will get a lot of insight on how to run the systems via this instruction. If you need assistance running Utilitarian in another environment please contact us .","title":"Installation"},{"location":"installation/#postgres","text":"We use Postgres as our database of choice. We recommend that you set up Postgres on a dedicated server or use a managed service for it. You can find out a lot about running Postgres online . Also make sure you have proper security settings and follow best practices. If you are running Postgres yourself you also want to set up a stable backup function . After you have set up postgres you will supply the connection string in the format: postgres://[user[:password]@][host][:port][,...][/dbname][?param1=value1&...] # Example postgres://myuser:mysecretpassword@localhost:5432/db_name Postgres is available as a docker container and if you also want to run Postgres via docker make sure you set up a volume for it so that you don't loose any of your data. docker pull postgres:10.7-alpine","title":"Postgres"},{"location":"installation/#rabbitmq","text":"RabbitMQ is a message broker for the AMQP protocol. Utilitarian uses it for inter-application communication and data processing. Checkout the official RabbitMQ site to learn how to run RabbitMQ or purchase a managed solution from, for example CloudAMQP . You will need to provide a similar connection string for RabbitMQ as for Postgres: amqp://[user[:password]@][host][:port][/vhost]] # Example amqp://guest:guest@localhost:5672// RabbitMQ can also be run as a container. Just be sure to add a volume for it so you don't loose any data and we recommend that you include the management plugin so that you have an interface for management and debugging if something is not working correctly. docker pull rabbitmq:3.7.13-management-alpine","title":"RabbitMQ"},{"location":"installation/#hardware","text":"We don\u2019t have any real numbers to tell you what kind of hardware you\u2019re going to need, but we\u2019ll help you make your decision based on existing usage from real customers. It all depends on how many meters you are managing in Utilitarian and how much data you collect from them. If you have a wide range of different meters you must also take into consideration that you will have multiple services of different kinds running in your environment. We provide means to scale horizontally but the database is still the single point of failure. Since you are free to set up the database the way your IT department or Ops team requires we leave this implementation detail to the customer.","title":"Hardware"},{"location":"installation/#monitoring","text":"We do not supply a standard solution to monitor the applications. All logs from the different applications are outputed on stdout via docker. So they are accessible via docker logs. You can then hook up the docker logs to different logging drivers, see the official docker documentation . There are several solutions to application and log monitoring. For example Elastic Stack or Splunk. Contact us if you want help setting this up for your installation. We are exposing a healthcheck endpoint at /_health/ that will return 200 OK if the the API is working correctly. The healthcheck can be disabled using the env variable HEALTHCHECK_DISABLED","title":"Monitoring"},{"location":"installation/#initial-setup-utilitarian-api","text":"","title":"Initial setup Utilitarian API"},{"location":"installation/#generate-application-secret_key","text":"Utilitarian needs a SECRET_KEY for cryptographic algorithms and signing. We recommend at least 50 chars. # Example generating SECRET_KEY with openssl openssl rand -base64 50 >> CZKcDahINwxy+eYzMItr+NZRqrONvMmJ12g+hF+W/QOMh/A4tRxhQ3onvRjJv47l Set the SECRET_KEY environment variable to this key.","title":"Generate application SECRET_KEY"},{"location":"installation/#migrate-the-database","text":"The first time you set up Utilitarian API you will need to migrate the database so all tables are present. Assuming you have started all services via docker-compose run the following command: docker-compose exec utilitarian_api sh -c \"python manage.py migrate\"","title":"Migrate the database"},{"location":"installation/#create-superuser","text":"Assuming you have started all services via docker-compose you should run the following command docker-compose exec utilitarian_api sh -c \"python manage.py createsuperuser\"","title":"Create Superuser"},{"location":"installation/#collect-static-assets","text":"Assuming you have started all services via docker-compose you should run the following command docker-compose exec utilitarian_api sh -c \"python manage.py collectstatic --no-input\"","title":"Collect static assets"},{"location":"installation/#compress-static-assets","text":"Assuming you have started all services via docker-compose you should run the following command docker-compose exec utilitarian_api sh -c \"python manage.py compress\"","title":"Compress static assets"},{"location":"meters/","text":"Meters # Meters we support Fiorentini # RSE/2001 LA # A NB-IoT Gas Meter. Uses an Italian companion standard to DLMS. Used in the first commercial rollout of NB-IoT Smart Meters in Sweden. Elster # EK 280 # Electronic volume conversion device with optional integrated communication module and configurable data interface. Protocol supported: LIS-200","title":"Meters"},{"location":"meters/#meters","text":"Meters we support","title":"Meters"},{"location":"meters/#fiorentini","text":"","title":"Fiorentini"},{"location":"meters/#rse2001-la","text":"A NB-IoT Gas Meter. Uses an Italian companion standard to DLMS. Used in the first commercial rollout of NB-IoT Smart Meters in Sweden.","title":"RSE/2001 LA"},{"location":"meters/#elster","text":"","title":"Elster"},{"location":"meters/#ek-280","text":"Electronic volume conversion device with optional integrated communication module and configurable data interface. Protocol supported: LIS-200","title":"EK 280"},{"location":"open_source/","text":"Open Source # We want Utilitarian to be a simple companion to our customers in their AMR operations. We provide documented interfaces and APIs to our services and messaging system. So you have the freedom of making use of the data as you see fit. For example if you need to make a special analytics service for some customers you can either get the data from the Utilitarian API or subscribe directly to it via the message broker. We provide some helpers to write your own integrations written in Python but since we are using AMQP and HTTP you can find implementations of those protocols in many programing languages and use the documentation in our helpers to speed up development of your own integrations in your language of choice. We also provide many libraries of the protocols we support as open source. Utilitarian Helpers # Utilitarian Queue Consumer # Check it out on GitHub: https://github.com/pwitab/utilitarian-queue-consumer The Utilitarian Queue Consumer is a micro framework to write consumers for the messages in Utilitarian. It gives you good default for consuming messages and producing new messages. AMR UM # Check it out on GitHub: https://github.com/pwitab/amr-um AMR UM (Unified Messaging for Automatic Meter Readings) is our attempt to have standard and well documented messaging framwork. In the repo you can find Python helpers to format the data and documentation on the different schemas used. Protocols # DLMS/COSEM # Check it out on GitHub: https://github.com/pwitab/dlms-cosem DLMS/COSEM (IEC 62056, EN13757-1) is the global standard for smart energy metering, control and management. It specifies an object-oriented data model, an application layer protocol and media-specific communication profiles.","title":"Open Source"},{"location":"open_source/#open-source","text":"We want Utilitarian to be a simple companion to our customers in their AMR operations. We provide documented interfaces and APIs to our services and messaging system. So you have the freedom of making use of the data as you see fit. For example if you need to make a special analytics service for some customers you can either get the data from the Utilitarian API or subscribe directly to it via the message broker. We provide some helpers to write your own integrations written in Python but since we are using AMQP and HTTP you can find implementations of those protocols in many programing languages and use the documentation in our helpers to speed up development of your own integrations in your language of choice. We also provide many libraries of the protocols we support as open source.","title":"Open Source"},{"location":"open_source/#utilitarian-helpers","text":"","title":"Utilitarian Helpers"},{"location":"open_source/#utilitarian-queue-consumer","text":"Check it out on GitHub: https://github.com/pwitab/utilitarian-queue-consumer The Utilitarian Queue Consumer is a micro framework to write consumers for the messages in Utilitarian. It gives you good default for consuming messages and producing new messages.","title":"Utilitarian Queue Consumer"},{"location":"open_source/#amr-um","text":"Check it out on GitHub: https://github.com/pwitab/amr-um AMR UM (Unified Messaging for Automatic Meter Readings) is our attempt to have standard and well documented messaging framwork. In the repo you can find Python helpers to format the data and documentation on the different schemas used.","title":"AMR UM"},{"location":"open_source/#protocols","text":"","title":"Protocols"},{"location":"open_source/#dlmscosem","text":"Check it out on GitHub: https://github.com/pwitab/dlms-cosem DLMS/COSEM (IEC 62056, EN13757-1) is the global standard for smart energy metering, control and management. It specifies an object-oriented data model, an application layer protocol and media-specific communication profiles.","title":"DLMS/COSEM"},{"location":"protocols/","text":"Protocols # The different protocols we support DLMS/COSEM # DLMS/COSEM (IEC 62056, EN13757-1) is the global standard for smart energy metering, control and management. It specifies an object-oriented data model, an application layer protocol and media-specific communication profiles. PWIT is developing an open source library for DLMS/COSEM IEC 62056-21 # IEC 62056-21 superseded IEC 61107 (sometimes just called IEC 1107). It is used for direct local data exchange. It has been designed to act as the protocol used when reading the meter via its optical port. But it is used with several medias, including sending the data over the internet. M-Bus # M-Bus (Meter-Bus) is a European standard (EN 13757-2 physical and link layer, EN 13757-3 application layer) for the remote reading of gas or electricity meters. M-Bus is also usable for other types of consumption meters. The M-Bus interface is made for communication on two wires, making it cost-effective. A radio variant of M-Bus (Wireless M-Bus) is also specified in EN 13757-4. Modbus # Modbus is a serial communications protocol originally used with programmable logic controllers (PLCs) but has become a de facto standard communication protocol and is now a commonly available means of connecting industrial electronic devices. Many meters that are not focused only on residential measurement are equipped with a Modbus port so that they can easily be used in industrial applications. ANSI C12.18 # ANSI C12.18 is an ANSI standard that describes a protocol used for two-way communications with a meter, mostly used in North American markets. LIS-200 # LIS-200 is a subset of IEC62056-21. It as implemented when the IEC62056-21 didn't have all the functionality needed. It is basically the same as IEC62056-21 in the flow but object identification is done differently. I-Flag # I-Flag is a proprietary protocol developed by Itron. It is used in many of Itrons products.","title":"Protocols"},{"location":"protocols/#protocols","text":"The different protocols we support","title":"Protocols"},{"location":"protocols/#dlmscosem","text":"DLMS/COSEM (IEC 62056, EN13757-1) is the global standard for smart energy metering, control and management. It specifies an object-oriented data model, an application layer protocol and media-specific communication profiles. PWIT is developing an open source library for DLMS/COSEM","title":"DLMS/COSEM"},{"location":"protocols/#iec-62056-21","text":"IEC 62056-21 superseded IEC 61107 (sometimes just called IEC 1107). It is used for direct local data exchange. It has been designed to act as the protocol used when reading the meter via its optical port. But it is used with several medias, including sending the data over the internet.","title":"IEC 62056-21"},{"location":"protocols/#m-bus","text":"M-Bus (Meter-Bus) is a European standard (EN 13757-2 physical and link layer, EN 13757-3 application layer) for the remote reading of gas or electricity meters. M-Bus is also usable for other types of consumption meters. The M-Bus interface is made for communication on two wires, making it cost-effective. A radio variant of M-Bus (Wireless M-Bus) is also specified in EN 13757-4.","title":"M-Bus"},{"location":"protocols/#modbus","text":"Modbus is a serial communications protocol originally used with programmable logic controllers (PLCs) but has become a de facto standard communication protocol and is now a commonly available means of connecting industrial electronic devices. Many meters that are not focused only on residential measurement are equipped with a Modbus port so that they can easily be used in industrial applications.","title":"Modbus"},{"location":"protocols/#ansi-c1218","text":"ANSI C12.18 is an ANSI standard that describes a protocol used for two-way communications with a meter, mostly used in North American markets.","title":"ANSI C12.18"},{"location":"protocols/#lis-200","text":"LIS-200 is a subset of IEC62056-21. It as implemented when the IEC62056-21 didn't have all the functionality needed. It is basically the same as IEC62056-21 in the flow but object identification is done differently.","title":"LIS-200"},{"location":"protocols/#i-flag","text":"I-Flag is a proprietary protocol developed by Itron. It is used in many of Itrons products.","title":"I-Flag"},{"location":"providers/","text":"Provider specific implementations # Some metering equipment providers have well implemented integrations besides from pure metering protocols. This can involve HTTP Push, SMS or FTP uploads. To make life simpler we want to be able to provide integrations with this kind of functionality and will work to implement as many as possible. Ongoing Development # We are currently not developing any provider specific implementations. If you are in need of an implementation please contact us .","title":"Providers"},{"location":"providers/#provider-specific-implementations","text":"Some metering equipment providers have well implemented integrations besides from pure metering protocols. This can involve HTTP Push, SMS or FTP uploads. To make life simpler we want to be able to provide integrations with this kind of functionality and will work to implement as many as possible.","title":"Provider specific implementations"},{"location":"providers/#ongoing-development","text":"We are currently not developing any provider specific implementations. If you are in need of an implementation please contact us .","title":"Ongoing Development"},{"location":"pwit/","text":"Palmlund Wahlgren Innovative Technology AB # Palmlund Wahlgren Innovative Technology AB (PWIT AB) is an engineering firm focused on delivering solutions and consultation services within the fields of automation, measurement technology and IT. By combining our strengths we have landed in the field of Internet of Things where we have been able to manage projects and build devices and software within the smart metering segment. We have been working with Swedish utility companies in local projects and EU-level projects where we have designed and implemented solutions for Real Time AMR (Automatic Meter Readings) and Next Generation MDM (Meter Data Management) using NoSQL-databases. We have taken full responsibility for the whole metering chain. From implementing protocol interpreters on embedded devices and in the Cloud to enable real-time metering on older energy meters to meter data management and integration to legacy Enterprise systems such as SAP for billing. Utilitarian is the result of our desire to make AMR more simpler for the end user and put the data in focus instead of the means to collect the data. We have used all our experience in the field to deliver a solution that can fit any size and type of utility company. Learn more about us","title":"PWIT AB"},{"location":"pwit/#palmlund-wahlgren-innovative-technology-ab","text":"Palmlund Wahlgren Innovative Technology AB (PWIT AB) is an engineering firm focused on delivering solutions and consultation services within the fields of automation, measurement technology and IT. By combining our strengths we have landed in the field of Internet of Things where we have been able to manage projects and build devices and software within the smart metering segment. We have been working with Swedish utility companies in local projects and EU-level projects where we have designed and implemented solutions for Real Time AMR (Automatic Meter Readings) and Next Generation MDM (Meter Data Management) using NoSQL-databases. We have taken full responsibility for the whole metering chain. From implementing protocol interpreters on embedded devices and in the Cloud to enable real-time metering on older energy meters to meter data management and integration to legacy Enterprise systems such as SAP for billing. Utilitarian is the result of our desire to make AMR more simpler for the end user and put the data in focus instead of the means to collect the data. We have used all our experience in the field to deliver a solution that can fit any size and type of utility company. Learn more about us","title":"Palmlund Wahlgren Innovative Technology AB"},{"location":"using_https_on_api/","text":"Run Utilitarian API under HTTPS # The main application does not provide any means to run under HTTPS. This is done via a reverse proxy like NginX or HAProxy. Having a reverse proxy also simplifies load balancing if you need to scale up the API. You can run it as a stand alone service or run it as docker container. We leave it up to the customer to define the way they want to terminate SSL/TLS and handle load balancing but will of course provide help if needed. Settings in Utilitarian API if running under HTTPS: # SESSION_COOKIE_SECURE should be set to true CSRF_COOKIE_SECURE should be set to true Depending on your proxy settings you should set the USE_X_FORWARDED_HOST , USE_X_FORWARDED_PORT and USE_X_FORWARDED_PROTO to true SECURE_HSTS_SECONDS should be set to 60 and when you have made sure it works properly it can be increased to a higher value","title":"Use HTTPS"},{"location":"using_https_on_api/#run-utilitarian-api-under-https","text":"The main application does not provide any means to run under HTTPS. This is done via a reverse proxy like NginX or HAProxy. Having a reverse proxy also simplifies load balancing if you need to scale up the API. You can run it as a stand alone service or run it as docker container. We leave it up to the customer to define the way they want to terminate SSL/TLS and handle load balancing but will of course provide help if needed.","title":"Run Utilitarian API under HTTPS"},{"location":"using_https_on_api/#settings-in-utilitarian-api-if-running-under-https","text":"SESSION_COOKIE_SECURE should be set to true CSRF_COOKIE_SECURE should be set to true Depending on your proxy settings you should set the USE_X_FORWARDED_HOST , USE_X_FORWARDED_PORT and USE_X_FORWARDED_PROTO to true SECURE_HSTS_SECONDS should be set to 60 and when you have made sure it works properly it can be increased to a higher value","title":"Settings in Utilitarian API if running under HTTPS:"}]}